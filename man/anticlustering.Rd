% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapper-anticlustering.R
\name{anticlustering}
\alias{anticlustering}
\title{Anticlustering}
\usage{
anticlustering(
  features = NULL,
  distances = NULL,
  K,
  objective = "distance",
  method = "exchange",
  preclustering = FALSE,
  nrep = 10,
  categories = NULL
)
}
\arguments{
\item{features}{A numeric vector, matrix or data.frame of data
points.  Rows correspond to elements and columns correspond to
features. A vector represents a single numeric feature.}

\item{distances}{Alternative data argument that can be used if
\code{features} is not passed. An N x N matrix representing the
pairwise dissimilarities between N elements. Larger values
indicate higher dissimilarity. Can be an object of class
\code{dist} (e.g., returned by \code{\link{dist}} or
\code{\link{as.dist}}) or a \code{matrix} where the entries of
the upper and lower triangular matrix represent the pairwise
dissimilarities.}

\item{K}{How many anticlusters should be created. Alternatively:
A vector of length N. Each entry in this vector
describes the initial grouping of an input element (as a number
between 1 and the number of groups).}

\item{objective}{The objective to be maximized. The option "distance"
(default) maximizes the cluster editing objective function; the
option "variance" maximizes the k-means objective function. See
details.}

\item{method}{One of "exchange" (default), "sampling", or "ilp".  See
details.}

\item{preclustering}{Boolean. Should a preclustering be conducted
before anticlusters are created? Defaults to \code{FALSE}. See
details.}

\item{nrep}{The number of repetitions for the random sampling
method. This argument only has an effect if \code{method} is
\code{"sampling"}.}

\item{categories}{A vector, data.frame or matrix representing one or
several categorical constraints. See details.}
}
\value{
A vector of length N that assigns a group (i.e, a number
    between 1 and K) to each input element.
}
\description{
Create sets of elements (anticlusters) that are as similar as 
possible by maximizing the heterogeneity within anticlusters.
}
\details{
This function is used to solve »K anticlustering«. That is,
K groups are created in such a way that all groups are
as similar as possible. In the standard case, groups of equal
size are returned. Adjust the \code{K} argument to create groups
of different size (see \code{\link{initialize_K}} for an example).

Set similarity is assessed using one of two objective functions:

- k-means *variance* objective, setting \code{objective = "variance"}

- cluster editing *distance* objective, setting \code{objective =
  "distance"}

The k-means objective measures the variance within
anticlusters---that is, the sum of the squared distances between each
element and its cluster center (see
\code{\link{variance_objective}}). The cluster editing objective
measures the sum of pairwise distances within anticlusters (see
\code{\link{distance_objective}}). Maximizing either of these
objectives will lead to similar groups (and this is what is
actually done when using this function). Minimization of the same
objectives would lead to a clustering, i.e., sets where elements are
similar within a set and different between sets.
(Such a clustering is also possible with the function
\code{\link{balanced_clustering}}.)

If the argument \code{features} is passed together with
\code{objective = "distance"}, the Euclidean distance is computed as
the basic unit of the anticluster editing objective. If a different
measure of dissimilarity is preferred, you may pass a self-generated
dissimiliarity matrix via the argument \code{distances}.

\strong{Exact anticlustering}

The optimal anticluster editing objective can be found via integer
linear programming. To this end, set \code{method = "ilp"}. To obtain
an optimal solution, a linear programming solver must be installed
and usable from R. The \code{anticlust} package supports the open
source GNU linear programming kit (called from the package
\code{Rglpk}) and the commercial solvers gurobi (called from the
package \code{gurobi}) and IBM CPLEX (called from the package
\code{Rcplex}). A license is needed to use one of the commercial
solvers. The optimal solution is retrieved by setting \code{objective
= "distance"}, \code{method = "ilp"} and \code{preclustering =
FALSE}. Use this combination of arguments only for small problem
sizes (maybe <= 30 elements).

To relax the optimality condition, it is possible to set the argument
\code{preclustering = TRUE}. In this case, the anticluster editing
objective is still optimized using integer linear programming, but a
preprocessing forbids very similar elements to be assigned to the
same anticluster. Thus, before the anticlustering objective is
optimized, a cluster analysis identifies small groups of similar
elements (pairs if K = 2, triplets if K = 3, and so forth). The
preclustering reduces the size of the solution space, making the ILP
approach applicable for larger problem instances. With preclustering,
optimality is no longer guaranteed, but the solution is usually
optimal or very close to optimal.

The variance criterion cannot be solved to optimality using integer
linear programming. However, it is possible to employ the function
\code{\link{generate_partitions}} to obtain optimal solutions for
small problem instances.

\strong{Heuristic anticlustering}

In addition to the exact approach---that is only feasible for small
N---the function employs two heuristic approaches. One option
is repeated random sampling (\code{method = "sampling"}): Across a
specified number of runs, each element is assigned to an anticluster
at random and the objective value associated with this assignment is
computed. In the end, the best assignment---the assignment that
maximized the objective function---is returned.  The other option
is the exchange method (\code{method = "exchange"}): Building on an
initial random assignment, elements are swapped between anticlusters
in such a way that each swap improves set similarity by the largest
amount that is possible in a situation (cf. Späth, 1986). The
swapping procedure is repeated for each element; because each
possible swap is investigated for each element, the total number of
exchanges grows quadratically with input size, rendering the exchange
method unsuitable for large N. Setting \code{preclustering = TRUE}
will limit the legal exchange partners to very similar elements,
resulting in improved run time while preserving a rather good
solution. This option is recommended for larger N. For very large N,
check out the function \code{\link{fast_anticlustering}} that was
specifically implemented for large data sets (or use the random
sampling method with few repetitions).


\strong{Categorical constraints}

The argument \code{categories} may induce categorical constraints.
The grouping variables indicated by \code{categories} will be
balanced out across anticlusters. Currently, this functionality is
only available in combination with the random sampling and exchange
method, but not with the exact ILP approach. Note that
it is currently \strong{not} possible to apply preclustering constraints
and categorical constraints at the same time.

\strong{Recommendations}

The following recommendations are provided on using this function:

\enumerate{
 \item If it is desired that the feature means are as similar as possible
     between sets, select \code{objective = "variance"}
 \item If the average similarity between elements in different sets
     should be maximized (i.e., making sets as a whole similar to
     each other), select \code{objective = "distance"}
 \item When the objective is \code{"distance"} and an exact approach
     is infeasible: select \code{method = "exchange"}; it is also
     possible to activate \code{preclustering = TRUE}, which improves
     run time and often does not even impair quality of the solution.
 \item Generally, the exchange method is preferred over random
     sampling. Use random sampling only for large data sets or if
     a fast solution is needed. However, even in that case, using
     the exchange method with preclustering activated or using the function
     \code{\link{fast_anticlustering}} is usually preferred.
}
}
\examples{

## Use anticlustering on the iris data set. Create sets of plants
## that are as similar as possible with regard to all four features
## of the iris plants

data(iris)
head(iris[, -5]) # these features are made similar across sets


## Optimize the variance criterion using the exchange method
anticlusters <- anticlustering(
  iris[, -5],
  K = 3,
  objective = "variance",
  method = "exchange"
)
# Compare feature means by anticluster
by(iris[, -5], anticlusters, function(x) round(colMeans(x), 2))
# Compare standard deviations by anticluster
by(iris[, -5], anticlusters, function(x) round(apply(x, 2, sd), 2))


## Optimize the cluster editing objective while activating preclustering
anticlusters <- anticlustering(
  iris[, -5],
  K = 3,
  method = "exchange",
  objective = "distance",
  preclustering = TRUE
)
by(iris[, -5], anticlusters, function(x) round(colMeans(x), 2))
# Anticluster editing (method = "distance") tends to make the
# standard deviations more similar, while k-means (method = "variance")
# tends to make the means more similar):
by(iris[, -5], anticlusters, function(x) round(apply(x, 2, sd), 2))



## Incorporate categorical restrictions:
anticlusters <- anticlustering(
  iris[, -5],
  K = 2,
  categories = iris[, 5],
  method = "sampling",
  nrep = 1
)
table(iris[, 5], anticlusters)

}
\references{
Grötschel, M., & Wakabayashi, Y. (1989). A cutting plane algorithm
for a clustering problem. Mathematical Programming, 45, 59-96.

Papenberg, M., & Klau, G. W. (2019, October 30). Using anticlustering
to partition a stimulus pool into equivalent parts.
https://doi.org/10.31234/osf.io/3razc

Späth, H. (1986). Anticlustering: Maximizing the variance criterion.
Control and Cybernetics, 15, 213-218.
}
\seealso{
\code{\link{fast_anticlustering}}

\code{\link{initialize_K}}

\code{\link{variance_objective}}

\code{\link{distance_objective}}
}
\author{
Martin Papenberg \email{martin.papenberg@hhu.de}
}
