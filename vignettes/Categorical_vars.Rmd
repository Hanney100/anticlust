---
title: "Using categorical variables with anticlustering"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using categorical variables with anticlustering}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(anticlust)
```

In this vignette I explore two ways to incorporate categorical variables with anticlustering. The main function of `anticlust` is `anticlustering()`, and it has an argument `categories`. It can be used easily enough: We just pass the numeric variables as first argument (`x`) and our categorical variable(s) to `categories`. I will use the penguin data set from the `palmerpenguins` package to illustrate this: 

```{r}
library(palmerpenguins)
# First exclude cases with missing values
df <- na.omit(penguins)
head(df)
nrow(df)
```

Let's call `anticlustering()` to divide the `r nrow(df)` penguins into 3 groups, using the penguins' sex as categorical variable:

```{r}
numeric_vars <- df[, c("bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g")]
groups <- anticlustering(
  numeric_vars, 
  K = 3,
  categories = df$sex,
  method = "local-maximum", # optimization algorithm
  objective = "variance" # k-plus anticlustering
)
```

Let's check out how well our categorical variables are balanced:

```{r}
# 1. Define function to compute relative frequency of category by group
row_margins <- function(tab) {
  prop.table(tab, 1) |> round(2)
}
table(groups, df$sex) # absolute values
row_margins(table(groups, df$sex)) # relative values
```

A perfect split! Similarly, we could use the species as categorical variable: 

```{r}
groups <- anticlustering(
  numeric_vars, 
  K = 3,
  categories = df$species,
  method = "local-maximum", 
  objective = "variance" 
)

table(groups, df$species) # absolute values
row_margins(table(groups, df$species)) # relative values
```

As good as it could be! Now, let's use both categorical variables at the same time:

```{r}
groups <- anticlustering(
  numeric_vars, 
  K = 3,
  categories = df[, c("species", "sex")],
  method = "local-maximum", 
  objective = "variance" 
)

table(groups, df$sex)
table(groups, df$species) 
row_margins(table(groups, df$sex))
row_margins(table(groups, df$species)) 
```

We see that the results for each categorical variable are worse than when we only considered one variable. This is because when giving multiple variable to `categories`, all columns are "merged" into a single column, and each combination of sex / species is treated as a separate category. Some information on the original variables is lost, and the results may become less optimal (while still pretty okay here). 

## K-plus anticlustering

K-means anticlustering offers a second possibility to distribute categorical variables evenly between groups. This approach can lead to better results when multiple categorical variables are available (and / or the group sizes are unequal). To achieve this, we first generate a matrix of the categorical variables in binary representation using the anticlust conveniece function `categories_to_binary()`. Because k-means anticlustering optimizes similarity with regard to means, using k-means on this binary matrix will make the proportion of each category in each group similar (because the mean of a binary variable is the proportion of 1s).

```{r}
binary_categories <- categories_to_binary(df[, c("species", "sex")], use_combinations = TRUE)
# see ?binary_categories
head(binary_categories)
```

```{r}
groups <- anticlustering(
  binary_categories,
  K = 3,
  standardize = TRUE,
  method = "local-maximum", 
  objective = "variance",
  repetitions = 10
)
table(groups, df$sex)
table(groups, df$species)
# Combination of the categorical variables:
table(groups, df$species, df$sex)
```

The results are quite convincing. In particular, the sex is better balanced than before using `categories`. If we have multiple categorical variables and / or unequal-sized groups, it may be useful to try out the k-means optimization version of including categorical variables, instead of (only) using the categories argument. 

However, note that in this case, we only evenly distributed the categorical variable between groups and did not consider the numeric variables. This is also possible, and we can do that in two different ways: (a) we first optimize similarity of the categorical variable between groups and then insert the assignment of categories as a "hard constraint" to `anticlustering()`; (b) we use simultaneous optimization with regard to numeric and categorical variables. We test both approaches in the following.

### (a) Sequential optimization

```{r}
groups <- anticlustering(
  binary_categories,
  K = 3,
  standardize = TRUE,
  method = "local-maximum", 
  objective = "variance",
  repetitions = 10
)
```

We now use the `groups` vector as input to the `K` argument as initial group assignment (where the categories are well balanced), and we also pass the two categorical variables to `categories` to ensure that the balancing of the categorical variable is not changed throughout the optimization algorithm:

```{r}
final_groups <- anticlustering(
  numeric_vars,
  K = groups,
  standardize = TRUE,
  method = "local-maximum", 
  objective = "variance",
  categories = df[, c("species", "sex")]
)

table(groups, df$sex)
table(groups, df$species)
mean_sd_tab(numeric_vars, final_groups)
```


The results are quite convincing. The balancing of the categorical variables remains as it was returned in the first step, where we only considered the categories in k-means anticlustering; in the second step, we then inserted the numeric variables. 

The following code extends the simultaneous optimization towards k-plus anticlustering (which ensures that standard deviations as well as means are similar between groups, and not only means, which is achieved via standard k-means anticlustering):

```{r}
final_groups <- anticlustering(
  kplus_moment_variables(numeric_vars, T = 2),
  K = groups,
  standardize = TRUE,
  method = "local-maximum", 
  objective = "variance",
  categories = df[, c("species", "sex")]
)

table(groups, df$sex)
table(groups, df$species)
mean_sd_tab(numeric_vars, final_groups)
```

We see that the standard deviations are also quite evenly matched between groups. 

### (b) Simultaneous optimization

Just pass all variables (representing binary categories and numeric variables) as one matrix to the first argument. Do not use the `categories` argument:

```{r}
final_groups <- anticlustering(
  cbind(kplus_moment_variables(numeric_vars, T = 2), binary_categories),
  K = groups,
  standardize = TRUE,
  method = "local-maximum", 
  objective = "variance",
  repetitions = 10
)

table(groups, df$sex)
table(groups, df$species)
mean_sd_tab(numeric_vars, final_groups)
```

Just try out the different approaches and see which one works best for you!

