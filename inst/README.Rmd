---
title: "Getting started with the anticlust package"
author: "Martin Papenberg"
date: "`r Sys.Date()`"
output:
  md_document:
  variant: gfm
---

# anticlust <a href='https://m-py.github.io/anticlust/'><img src='man/figures/anticlustStickerV1-0.svg' align="right" height="160" /></a>

Anticlustering partitions a pool of elements into clusters (or *anticlusters*) with the goal of achieving high between-cluster similarity and high within-cluster heterogeneity. This is accomplished by maximizing instead of minimizing a clustering objective function, such as the intra-cluster variance (used in k-means clustering) or the sum of pairwise distances within clusters. The package `anticlust` implements anticlustering algorithms as described in Papenberg and Klau (2021; https://doi.org/10.1037/met0000301). It was originally developed to stimuli items to experimental conditions in experimental psychology, but it can be applied whenever a user requires that a given set of elements has to be partitioned groups that have to be as similar as possible, or when the within-group heterogeneity should be high.

```{r setup, include = FALSE}
library("anticlust")

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.cap = "",
  message = FALSE,
  warning = FALSE
)

# set.seed(123)

knitr::opts_chunk$set(
  fig.path = "man/figures/"
)

```

## Installation

The stable release of `anticlust` is available from [CRAN](https://CRAN.R-project.org/package=anticlust) and can be installed via:

```R
install.packages("anticlust")
```

A (potentially more recent) version of anticlust can also be installed directly via Github:

```R
library("remotes") # if not available: install.packages("remotes")
install_github("m-Py/anticlust")
```

## Citation

If you use `anticlust` in your research, it would be courteous if you cite the following reference:

Papenberg, M., & Klau, G. W. (2021). Using anticlustering to partition data sets into equivalent parts. *Psychological Methods, 26*(2), 161--174. https://doi.org/10.1037/met0000301

Another great way of showing your appreciation of `anticlust` is to leave a star on this Github repository.

## How do I learn about `anticlust`

This README contains some basic information on the `R` package `anticlust`. More information is available via the following sources:

- A paper is available describing the theoretical background of anticlustering and the `anticlust` package in detail (https://doi.org/10.1037/met0000301). The freely available preprint can be retrieved from https://psyarxiv.com/3razc/.

- The `R` documentation of the main functions is actually quite rich and up to date, so you should definitely check that out when using the `anticlust` package (primarily `?anticlustering`, `?kplus_anticlustering`, `?balanced_clustering`, and `?matching`).

- The [package website](https://m-py.github.io/anticlust/) contains most relevant documentation. This includes a [vignette](https://m-py.github.io/anticlust/articles/stimulus-selection.html) detailing how to use the anticlust package for stimulus selection in experiments and documentation for the main `anticlust` functions. Note that the homepage is not completely up to date right now; this should change in the future, and additional vignettes are planned.

## A quick start

In this initial example, I use the main function `anticlustering()` to create three similar sets of plants using the classical iris data set:

```{r}
# load the package via
library("anticlust")

anticlusters <- anticlustering(
  iris[, -5],
  K = 3,
  objective = "variance",
  method = "local-maximum"
)

# The output is a vector that assigns a group (i.e, a number
# between 1 and K) to each input element:
anticlusters

# Each group has the same number of items:
table(anticlusters)

# Compare the feature means by anticluster:
by(iris[, -5], anticlusters, function(x) round(colMeans(x), 2))
```

As illustrated in the example, we can use the function `anticlustering()` to create similar sets of elements. In this case "similar" primarily means that the mean values of the variables are pretty much the same across three groups. The function `anticlustering()` takes as input a data table describing the elements that should be assigned to sets. In the data table, each row represents an element, for example a person, word or a photo. Each column is a numeric variable describing one of the elements' features. (Alternatively, it is also possible to pass a distance matrix describing the pairwise dissimilarity between elements.) The number of groups is specified through the argument `K`. The argument `objective` specifies how between-group similarity is computed; the argument `method` specifies the algorithm by which this measure is optimized. See the documentation `?anticlustering` for more details.

To quantify cluster similarity, `anticlust` employs one of several measures that have been developed in the context of cluster analysis:

- the cluster editing "diversity" objective, setting `objective = "diversity"` (default)
- the k-means "variance" objective, setting `objective = "variance"`
- the "k-plus" objective, an extension of the k-means variance criterion, setting `objective = "kplus"`
- the "dispersion" objective (the minimum distance between any two elements within the same cluster), setting `objective = "dispersion"`

The anticlustering objectives are described in detail in the documentation (`?diversity_objective`, `?variance_objective`, `?kplus_anticlustering`, `?dispersion_objective`) and the references therein. It is also possible to optimize user-defined measures of cluster similarity, which is also described in the documentation (`?anticlustering`).

## Categorical variables

Sometimes, it is required that sets are not only similar with regard to
some numeric variables, but we also want to ensure that each set
contains an equal number of elements of a certain category. Coming back
to the initial iris data set, we may want to require that each set has a
balanced number of plants of the three iris species. To this end, we can
use the argument `categories` as follows:

```{r}
anticlusters <- anticlustering(
  iris[, -5],
  K = 3,
  categories = iris$Species
)

## The species are as balanced as possible across anticlusters:
table(anticlusters, iris$Species)

```

## Matching and clustering

Anticlustering creates sets of dissimilar elements; the heterogenity within anticlusters is maximized. This is the opposite of clustering problems that strive for high within-cluster similarity and good separation between clusters. The `anticlust` package also provides functions for "classical" clustering applications: `balanced_clustering()` creates sets of elements that are similar while ensuring that clusters are of equal size. This is an example:

```{r clustering}
# Generate random data, cluster the data set and visualize results
N <- 1400
lds <- data.frame(var1 = rnorm(N), var2 = rnorm(N))
cl <- balanced_clustering(lds, K = 7)
plot_clusters(lds, clusters = cl, show_axes = TRUE)
```

The function `matching()` is very similar, but is usually used to find small groups of similar elements, e.g., triplets as in this example:

```{r matching}
# Generate random data and find triplets of similar elements:
N <- 120
lds <- data.frame(var1 = rnorm(N), var2 = rnorm(N))
triplets <- matching(lds, p = 3)
plot_clusters(
  lds,
  clusters = triplets,
  within_connection = TRUE,
  show_axes = TRUE
)
```

## Questions and suggestions

If you have any question on the `anticlust` package or any suggestions (which are greatly appreciated), I encourage you to contact me via email (martin.papenberg@hhu.de) or [Twitter](https://twitter.com/MPapenberg), or to open an [issue on the Github repository](https://github.com/m-Py/anticlust/issues).
